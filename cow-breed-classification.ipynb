{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13102064,"sourceType":"datasetVersion","datasetId":8299526},{"sourceId":13120412,"sourceType":"datasetVersion","datasetId":3103253},{"sourceId":13195484,"sourceType":"datasetVersion","datasetId":8362331}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- STEP 1: SETUP & MERGE DATASETS ---\n!pip install ultralytics -q\n!pip install opencv-python pycocotools matplotlib\n\n# --- CORE IMPORTS ---\nimport os, shutil, io, random, cv2, numpy as np, pandas as pd\nfrom PIL import Image, ImageFilter\nimport matplotlib.pyplot as plt\n\n\n# --- Torchvision ---\nfrom torchvision import transforms, datasets, models\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# --- For K-Fold ---\nfrom sklearn.model_selection import StratifiedKFold\nprint(\"✅ All imports done\")\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score, f1_score\n\nimport torch.optim as optim\nfrom torch.nn import CrossEntropyLoss\n\n\n#Multiprocessing\n!pip install mpire\nimport mpire as _noop  # no-op import to keep dependencies explicit (optional)\nimport multiprocessing as mp\nimport tqdm\n\n#dataset creation\nimport json\nimport subprocess, sys, glob\n\n# --- YOLO ---\nfrom ultralytics import YOLO\n\n#-----------------------------------------------------\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:04:11.265668Z","iopub.execute_input":"2025-09-30T16:04:11.266427Z","iopub.status.idle":"2025-09-30T16:05:50.675278Z","shell.execute_reply.started":"2025-09-30T16:04:11.266403Z","shell.execute_reply":"2025-09-30T16:05:50.674447Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.10)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n✅ All imports done\nCollecting mpire\n  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: pygments>=2.0 in /usr/local/lib/python3.11/dist-packages (from mpire) (2.19.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from mpire) (4.67.1)\nDownloading mpire-2.10.2-py3-none-any.whl (272 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: mpire\nSuccessfully installed mpire-2.10.2\nCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nDone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\n\n# Dataset paths\nbovine_dataset = '/kaggle/input/indian-bovine-breeds/'\ncalf_dataset   = '/kaggle/input/indian-cow-calf-images/'\n\n# Check existence\nassert os.path.exists(bovine_dataset), \"Bovine dataset not found!\"\nassert os.path.exists(calf_dataset), \"Calf dataset not found!\"\n\n# Merged dataset base\nmerged_base = '/kaggle/working/merged_dataset'\ncsv_path = os.path.join(merged_base, \"labels.csv\")\n\n# Preprocessed dataset already exists\nif os.path.exists(merged_base) and os.path.exists(csv_path):\n    print(\"✅ Preprocessed dataset found, loading CSV...\")\n    df = pd.read_csv(csv_path)\nelse:\n    if os.path.exists(merged_base):\n        shutil.rmtree(merged_base)\n    os.makedirs(merged_base, exist_ok=True)\n    print(\"⚙ Dataset will be preprocessed for all breeds (including calves).\")\n    \n    all_rows = []\n\n    # Adult bovine images\n    for root, dirs, files in os.walk(bovine_dataset):\n        breed = os.path.basename(root)\n        if breed == os.path.basename(os.path.normpath(bovine_dataset)):\n            continue\n        for img in sorted(files):\n            if img.lower().endswith(('.jpg','.jpeg','.png')):\n                all_rows.append([os.path.join(breed, img), breed, 0])\n\n    # Calf images — ensure all images counted\n    for root, dirs, files in os.walk(calf_dataset):\n        for img in sorted(files):\n            if img.lower().endswith(('.jpg','.jpeg','.png')):\n                all_rows.append([os.path.join(\"calf\", img), \"calf\", 1])\n\n    df = pd.DataFrame(all_rows, columns=[\"image_path\",\"breed\",\"is_calf\"])\n    df.to_csv(csv_path, index=False)\n    print(f\"✅ Preprocessing complete. CSV saved at {csv_path}\")\n\n# Display number of images per breed\nprint(\"\\nNumber of images per breed (including calves):\")\ndisplay(df['breed'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:05:50.676800Z","iopub.execute_input":"2025-09-30T16:05:50.677185Z","iopub.status.idle":"2025-09-30T16:06:08.574568Z","shell.execute_reply.started":"2025-09-30T16:05:50.677165Z","shell.execute_reply":"2025-09-30T16:06:08.573622Z"}},"outputs":[{"name":"stdout","text":"⚙ Dataset will be preprocessed for all breeds (including calves).\n✅ Preprocessing complete. CSV saved at /kaggle/working/merged_dataset/labels.csv\n\nNumber of images per breed (including calves):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"breed\nSahiwal              439\nGir                  372\nHolstein_Friesian    328\nAyrshire             234\nBrown_Swiss          225\nTharparkar           217\nJersey               203\nOngole               191\nHallikar             186\nNagpuri              182\nKankrej              178\nMurrah               173\nRed_Dane             167\nRed_Sindhi           162\nRathi                149\nVechur               140\nKrishna_Valley       136\nHariana              129\nPulikulam            124\nToda                 124\nGuernsey             119\nKhillari             113\nBanni                108\nMalnad_gidda         107\nJaffrabadi           101\nAlambadi              99\nDeoni                 99\nKasargod              95\nAmritmahal            94\nMehsana               94\nBargur                93\nKangayam              91\nNili_Ravi             88\nNagori                88\nBhadawari             86\nNimari                84\nDangi                 82\nUmblachery            76\nSurti                 59\nKenkatha              55\ncalf                  47\nKherigarh             36\nName: count, dtype: int64"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Count images per breed and sort descending\nbreed_counts = df['breed'].value_counts()\nsorted_breeds = breed_counts.index.tolist()\nsorted_counts = breed_counts.values.tolist()\n\n# Dictionary to store checkboxes\nbreed_checkboxes = {}\ncheckbox_widgets = []\n\n# Create checkbox for each breed\nfor breed, count in zip(sorted_breeds, sorted_counts):\n    cb = widgets.Checkbox(\n        value=True,  # default selected\n        description=f\"{breed} ({count} images)\",\n        indent=False\n    )\n    breed_checkboxes[breed] = cb\n    checkbox_widgets.append(cb)\n\n# Vertical box layout\nbreed_box = widgets.VBox(checkbox_widgets, layout=widgets.Layout(max_height='300px', overflow='auto'))\ndisplay(breed_box)\n\n# Button to confirm selection\nconfirm_btn = widgets.Button(description=\"Confirm Selection\", button_style='success')\nout = widgets.Output()\ndisplay(confirm_btn, out)\n\n# Internal variable to store selected breeds\nselected_breeds_for_training = []\n\ndef on_confirm_clicked(b):\n    global selected_breeds_for_training\n    selected_breeds_for_training = [breed for breed, cb in breed_checkboxes.items() if cb.value]\n    with out:\n        clear_output()\n        print(f\"✅ Selected breeds for training: {selected_breeds_for_training}\")\n\nconfirm_btn.on_click(on_confirm_clicked)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:06:08.575488Z","iopub.execute_input":"2025-09-30T16:06:08.575807Z","iopub.status.idle":"2025-09-30T16:06:08.666821Z","shell.execute_reply.started":"2025-09-30T16:06:08.575781Z","shell.execute_reply":"2025-09-30T16:06:08.666019Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Checkbox(value=True, description='Sahiwal (439 images)', indent=False), Checkbox(value=True, de…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"382add197412400893c2dd897aae70ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(button_style='success', description='Confirm Selection', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcd6425f12f24a9dbf73d14104194e05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8d30968dc0e44cab039c83abf9c2b97"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Load YOLOv8 model\n# You can use 'yolov8n.pt' for fast inference or your custom trained model\ndef load_yolo_on_device(device_id):\n    device = f\"cuda:{device_id}\" if torch.cuda.is_available() else \"cpu\"\n    model = YOLO('yolov8n.pt')  # replace with custom weights if available\n    model.to(device)\n    return model, device\n\nprint(\"✅ YOLO loader defined for multiple GPUs\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:06:58.062942Z","iopub.execute_input":"2025-09-30T16:06:58.063244Z","iopub.status.idle":"2025-09-30T16:06:58.069062Z","shell.execute_reply.started":"2025-09-30T16:06:58.063206Z","shell.execute_reply":"2025-09-30T16:06:58.068361Z"}},"outputs":[{"name":"stdout","text":"✅ YOLO loader defined for multiple GPUs\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def crop_with_yolo(img_path, save_path, model, device, target_size=(300, 300)):\n    \"\"\"\n    Detect largest cow using YOLO on a specific GPU and save cropped image.\n    \"\"\"\n    image = cv2.imread(img_path)\n    if image is None:\n        print(f\"⚠️ Could not read image: {img_path}\")\n        return False\n\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    results = model.predict(image_rgb, device=device, verbose=False)[0]\n\n    boxes = results.boxes.xyxy.cpu().numpy() if len(results.boxes) > 0 else []\n    if len(boxes) == 0:\n        return False\n\n    # Take the largest box (area)\n    areas = [(x2-x1)*(y2-y1) for x1, y1, x2, y2 in boxes]\n    largest_idx = np.argmax(areas)\n    x1, y1, x2, y2 = [int(c) for c in boxes[largest_idx]]\n\n    crop = image[y1:y2, x1:x2]\n    if crop.size == 0:\n        return False\n\n    # Resize to target size\n    crop_resized = cv2.resize(crop, target_size)\n    Image.fromarray(cv2.cvtColor(crop_resized, cv2.COLOR_BGR2RGB)).save(save_path)\n    return True\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:07:00.711465Z","iopub.execute_input":"2025-09-30T16:07:00.711752Z","iopub.status.idle":"2025-09-30T16:07:00.719006Z","shell.execute_reply.started":"2025-09-30T16:07:00.711731Z","shell.execute_reply":"2025-09-30T16:07:00.718283Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"#-----not needed---\ndef process_image(args):\n    src, dst, breed, is_calf, device_id = args\n    try:\n        mask_generator, device = load_sam_on_device(device_id)\n        if crop_with_sam(src, dst, mask_generator, device, max_dim=512):\n            return [os.path.join(breed, os.path.basename(dst)), breed, is_calf]\n    except Exception as e:\n        print(f\"⚠️ Error {src}: {e}\")\n    return None\nprint(\"DONE\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:07:03.710913Z","iopub.execute_input":"2025-09-30T16:07:03.711204Z","iopub.status.idle":"2025-09-30T16:07:03.716791Z","shell.execute_reply.started":"2025-09-30T16:07:03.711181Z","shell.execute_reply":"2025-09-30T16:07:03.716166Z"}},"outputs":[{"name":"stdout","text":"DONE\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"\n\n# Merged dataset base\nmerged_base = '/kaggle/working/merged_dataset'\ncsv_path = os.path.join(merged_base, \"labels.csv\")\n\nos.makedirs(merged_base, exist_ok=True)\nall_tasks = []\n\n# Adult bovine images\nfor root, dirs, files in os.walk(bovine_dataset):\n    breed = os.path.basename(root)\n    if breed not in selected_breeds_for_training:\n        continue\n    target_dir = os.path.join(merged_base, breed)\n    os.makedirs(target_dir, exist_ok=True)\n    for img in sorted(files):\n        if img.lower().endswith(('.jpg','.jpeg','.png')):\n            src = os.path.join(root,img)\n            dst = os.path.join(target_dir,img)\n            all_tasks.append((src,dst,breed,0))\n\n# Calf images\n# Calf images\n# Calf images\nif 'calf' in selected_breeds_for_training:\n    calf_target = os.path.join(merged_base,'calf')\n    os.makedirs(calf_target, exist_ok=True)\n    for img in sorted(os.listdir(calf_dataset)):\n        if img.lower().endswith(('.jpg','.jpeg','.png')):\n            src = os.path.join(calf_dataset,img)\n            dst = os.path.join(calf_target,img)\n            all_tasks.append((src,dst,'calf',1))\n\n\nprint(f\"Total images to process: {len(all_tasks)}\")\n\n# Distribute tasks across GPUs\ngpu_count = torch.cuda.device_count()\nif gpu_count == 0:\n    raise RuntimeError(\"No CUDA GPUs found.\")\ntasks_per_gpu = {i:[] for i in range(gpu_count)}\nfor i, task in enumerate(all_tasks):\n    gpu_id = i % gpu_count\n    tasks_per_gpu[gpu_id].append(task)\n\nprint(f\"✅ Tasks distributed across {gpu_count} GPUs\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:07:06.795570Z","iopub.execute_input":"2025-09-30T16:07:06.795824Z","iopub.status.idle":"2025-09-30T16:07:12.674169Z","shell.execute_reply.started":"2025-09-30T16:07:06.795805Z","shell.execute_reply":"2025-09-30T16:07:12.673402Z"}},"outputs":[{"name":"stdout","text":"Total images to process: 2755\n✅ Tasks distributed across 2 GPUs\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"all_rows = []\n\nfor gpu_id in range(gpu_count):\n    tasks = tasks_per_gpu[gpu_id]\n    if not tasks:\n        print(f\"GPU {gpu_id} has 0 tasks — skipping.\")\n        continue\n\n    print(f\"\\n--- Processing {len(tasks)} images on GPU {gpu_id} ---\")\n    try:\n        torch.cuda.set_device(gpu_id)\n    except Exception:\n        pass\n\n    # Load YOLO model on this GPU\n    model, device = load_yolo_on_device(gpu_id)\n\n    pbar = tqdm.tqdm(tasks, desc=f\"GPU {gpu_id}\", position=gpu_id, leave=True)\n    for src,dst,breed,is_calf in pbar:\n        try:\n            ok = crop_with_yolo(src,dst,model,device)\n            if ok:\n                all_rows.append([os.path.join(breed, os.path.basename(dst)), breed, is_calf])\n        except Exception as e:\n            print(f\"⚠ Error processing {src}: {e}\")\n\n    # Free GPU memory\n    try:\n        del model\n        torch.cuda.empty_cache()\n    except Exception:\n        pass\n\n# Save CSV\nif all_rows:\n    df_out = pd.DataFrame(all_rows, columns=[\"image_path\",\"breed\",\"is_calf\"])\n    df_out.to_csv(csv_path, index=False)\n    df = df_out\n    print(\"✅ Preprocessing complete — CSV saved at:\", csv_path)\n    print(df['breed'].value_counts())\nelse:\n    print(\"⚠ No images were successfully processed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:07:16.147305Z","iopub.execute_input":"2025-09-30T16:07:16.147849Z","iopub.status.idle":"2025-09-30T16:08:59.867475Z","shell.execute_reply.started":"2025-09-30T16:07:16.147827Z","shell.execute_reply":"2025-09-30T16:08:59.866733Z"}},"outputs":[{"name":"stdout","text":"\n--- Processing 1378 images on GPU 0 ---\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 75.1MB/s 0.1s\n","output_type":"stream"},{"name":"stderr","text":"GPU 0: 100%|██████████| 1378/1378 [00:50<00:00, 27.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Processing 1377 images on GPU 1 ---\n","output_type":"stream"},{"name":"stderr","text":"\nGPU 1:   0%|          | 0/1377 [00:00<?, ?it/s]\u001b[A\nGPU 1:   0%|          | 1/1377 [00:00<02:23,  9.57it/s]\u001b[A\nGPU 1:   0%|          | 4/1377 [00:00<01:08, 19.95it/s]\u001b[A\nGPU 1:   1%|          | 7/1377 [00:00<01:07, 20.17it/s]\u001b[A\nGPU 1:   1%|          | 11/1377 [00:00<01:10, 19.36it/s]\u001b[A\nGPU 1:   1%|          | 16/1377 [00:00<00:52, 26.05it/s]\u001b[A\nGPU 1:   1%|▏         | 19/1377 [00:00<00:54, 25.05it/s]\u001b[A\nGPU 1:   2%|▏         | 24/1377 [00:00<00:44, 30.38it/s]\u001b[A\nGPU 1:   2%|▏         | 28/1377 [00:01<00:49, 27.07it/s]\u001b[A\nGPU 1:   2%|▏         | 33/1377 [00:01<00:43, 30.89it/s]\u001b[A\nGPU 1:   3%|▎         | 37/1377 [00:01<00:49, 26.90it/s]\u001b[A\nGPU 1:   3%|▎         | 42/1377 [00:01<00:52, 25.58it/s]\u001b[A\nGPU 1:   3%|▎         | 45/1377 [00:01<00:51, 25.97it/s]\u001b[A\nGPU 1:   4%|▎         | 49/1377 [00:01<00:46, 28.57it/s]\u001b[A\nGPU 1:   4%|▍         | 54/1377 [00:01<00:40, 32.50it/s]\u001b[A\nGPU 1:   4%|▍         | 58/1377 [00:02<00:38, 33.94it/s]\u001b[A\nGPU 1:   5%|▍         | 63/1377 [00:02<00:36, 35.91it/s]\u001b[A\nGPU 1:   5%|▍         | 68/1377 [00:02<00:34, 37.97it/s]\u001b[A\nGPU 1:   5%|▌         | 72/1377 [00:02<00:35, 36.61it/s]\u001b[A\nGPU 1:   6%|▌         | 76/1377 [00:02<00:38, 33.88it/s]\u001b[A\nGPU 1:   6%|▌         | 81/1377 [00:02<00:35, 36.41it/s]\u001b[A\nGPU 1:   6%|▌         | 86/1377 [00:02<00:33, 38.29it/s]\u001b[A\nGPU 1:   7%|▋         | 90/1377 [00:02<00:35, 35.88it/s]\u001b[A\nGPU 1:   7%|▋         | 94/1377 [00:03<00:37, 34.32it/s]\u001b[A\nGPU 1:   7%|▋         | 99/1377 [00:03<00:37, 34.02it/s]\u001b[A\nGPU 1:   7%|▋         | 103/1377 [00:03<00:36, 34.98it/s]\u001b[A\nGPU 1:   8%|▊         | 108/1377 [00:03<00:34, 37.05it/s]\u001b[A\nGPU 1:   8%|▊         | 112/1377 [00:03<00:33, 37.22it/s]\u001b[A\nGPU 1:   8%|▊         | 116/1377 [00:03<00:40, 31.27it/s]\u001b[A\nGPU 1:   9%|▊         | 120/1377 [00:03<00:38, 32.97it/s]\u001b[A\nGPU 1:   9%|▉         | 125/1377 [00:04<00:42, 29.44it/s]\u001b[A\nGPU 1:   9%|▉         | 129/1377 [00:04<01:01, 20.45it/s]\u001b[A\nGPU 1:  10%|▉         | 132/1377 [00:04<01:02, 20.06it/s]\u001b[A\nGPU 1:  10%|▉         | 135/1377 [00:04<01:14, 16.66it/s]\u001b[A\nGPU 1:  10%|▉         | 137/1377 [00:04<01:15, 16.40it/s]\u001b[A\nGPU 1:  10%|█         | 140/1377 [00:05<01:11, 17.32it/s]\u001b[A\nGPU 1:  10%|█         | 142/1377 [00:05<01:26, 14.34it/s]\u001b[A\nGPU 1:  10%|█         | 144/1377 [00:05<01:20, 15.30it/s]\u001b[A\nGPU 1:  11%|█         | 146/1377 [00:05<01:27, 14.01it/s]\u001b[A\nGPU 1:  11%|█         | 148/1377 [00:05<01:26, 14.14it/s]\u001b[A\nGPU 1:  11%|█         | 150/1377 [00:05<01:28, 13.84it/s]\u001b[A\nGPU 1:  11%|█         | 152/1377 [00:06<01:40, 12.16it/s]\u001b[A\nGPU 1:  11%|█         | 154/1377 [00:06<01:38, 12.46it/s]\u001b[A\nGPU 1:  11%|█▏        | 156/1377 [00:06<01:48, 11.23it/s]\u001b[A\nGPU 1:  12%|█▏        | 161/1377 [00:06<01:08, 17.81it/s]\u001b[A\nGPU 1:  12%|█▏        | 165/1377 [00:06<00:54, 22.33it/s]\u001b[A\nGPU 1:  12%|█▏        | 169/1377 [00:06<00:47, 25.48it/s]\u001b[A\nGPU 1:  13%|█▎        | 174/1377 [00:06<00:40, 29.73it/s]\u001b[A\nGPU 1:  13%|█▎        | 179/1377 [00:07<00:35, 33.41it/s]\u001b[A\nGPU 1:  13%|█▎        | 183/1377 [00:07<00:35, 33.84it/s]\u001b[A\nGPU 1:  14%|█▎        | 187/1377 [00:07<00:42, 28.05it/s]\u001b[A\nGPU 1:  14%|█▍        | 191/1377 [00:07<00:40, 29.53it/s]\u001b[A\nGPU 1:  14%|█▍        | 195/1377 [00:07<00:44, 26.51it/s]\u001b[A\nGPU 1:  14%|█▍        | 199/1377 [00:07<00:42, 27.74it/s]\u001b[A\nGPU 1:  15%|█▍        | 203/1377 [00:07<00:40, 28.95it/s]\u001b[A\nGPU 1:  15%|█▌        | 207/1377 [00:08<00:38, 30.27it/s]\u001b[A\nGPU 1:  15%|█▌        | 211/1377 [00:08<00:36, 32.17it/s]\u001b[A\nGPU 1:  16%|█▌        | 215/1377 [00:08<00:52, 22.28it/s]\u001b[A\nGPU 1:  16%|█▌        | 218/1377 [00:08<00:54, 21.24it/s]\u001b[A\nGPU 1:  16%|█▌        | 221/1377 [00:08<00:57, 20.21it/s]\u001b[A\nGPU 1:  16%|█▋        | 225/1377 [00:08<00:50, 22.91it/s]\u001b[A\nGPU 1:  17%|█▋        | 229/1377 [00:09<01:00, 19.13it/s]\u001b[A\nGPU 1:  17%|█▋        | 233/1377 [00:09<00:55, 20.61it/s]\u001b[A\nGPU 1:  17%|█▋        | 237/1377 [00:09<00:51, 22.24it/s]\u001b[A\nGPU 1:  18%|█▊        | 241/1377 [00:09<00:46, 24.60it/s]\u001b[A\nGPU 1:  18%|█▊        | 246/1377 [00:09<00:39, 28.32it/s]\u001b[A\nGPU 1:  18%|█▊        | 250/1377 [00:09<00:45, 24.83it/s]\u001b[A\nGPU 1:  19%|█▊        | 255/1377 [00:10<00:39, 28.56it/s]\u001b[A\nGPU 1:  19%|█▉        | 259/1377 [00:10<00:40, 27.35it/s]\u001b[A\nGPU 1:  19%|█▉        | 262/1377 [00:10<00:43, 25.78it/s]\u001b[A\nGPU 1:  19%|█▉        | 265/1377 [00:10<00:48, 22.97it/s]\u001b[A\nGPU 1:  19%|█▉        | 268/1377 [00:10<00:59, 18.53it/s]\u001b[A\nGPU 1:  20%|█▉        | 271/1377 [00:11<01:35, 11.64it/s]\u001b[A\nGPU 1:  20%|█▉        | 273/1377 [00:11<01:44, 10.59it/s]\u001b[A\nGPU 1:  20%|█▉        | 275/1377 [00:11<01:38, 11.20it/s]\u001b[A\nGPU 1:  20%|██        | 277/1377 [00:11<01:33, 11.75it/s]\u001b[A\nGPU 1:  20%|██        | 279/1377 [00:12<01:46, 10.32it/s]\u001b[A\nGPU 1:  20%|██        | 281/1377 [00:12<01:55,  9.45it/s]\u001b[A\nGPU 1:  21%|██        | 283/1377 [00:12<01:39, 11.01it/s]\u001b[A\nGPU 1:  21%|██        | 285/1377 [00:12<01:46, 10.25it/s]\u001b[A\nGPU 1:  21%|██        | 287/1377 [00:12<01:48, 10.01it/s]\u001b[A\nGPU 1:  21%|██        | 289/1377 [00:13<01:54,  9.52it/s]\u001b[A\nGPU 1:  21%|██        | 291/1377 [00:13<02:00,  9.04it/s]\u001b[A\nGPU 1:  21%|██▏       | 294/1377 [00:13<01:36, 11.19it/s]\u001b[A\nGPU 1:  21%|██▏       | 296/1377 [00:13<01:29, 12.06it/s]\u001b[A\nGPU 1:  22%|██▏       | 298/1377 [00:13<01:26, 12.51it/s]\u001b[A\nGPU 1:  22%|██▏       | 301/1377 [00:13<01:07, 15.95it/s]\u001b[A\nGPU 1:  22%|██▏       | 305/1377 [00:14<00:51, 20.76it/s]\u001b[A\nGPU 1:  23%|██▎       | 310/1377 [00:14<00:38, 27.50it/s]\u001b[A\nGPU 1:  23%|██▎       | 316/1377 [00:14<00:30, 34.80it/s]\u001b[A\nGPU 1:  23%|██▎       | 322/1377 [00:14<00:25, 40.86it/s]\u001b[A\nGPU 1:  24%|██▍       | 328/1377 [00:14<00:23, 45.16it/s]\u001b[A\nGPU 1:  24%|██▍       | 334/1377 [00:14<00:21, 48.73it/s]\u001b[A\nGPU 1:  25%|██▍       | 340/1377 [00:14<00:20, 50.96it/s]\u001b[A\nGPU 1:  25%|██▌       | 346/1377 [00:14<00:19, 52.23it/s]\u001b[A\nGPU 1:  26%|██▌       | 352/1377 [00:14<00:19, 53.39it/s]\u001b[A\nGPU 1:  26%|██▌       | 358/1377 [00:15<00:19, 53.16it/s]\u001b[A\nGPU 1:  26%|██▋       | 364/1377 [00:15<00:18, 54.30it/s]\u001b[A\nGPU 1:  27%|██▋       | 370/1377 [00:15<00:18, 54.85it/s]\u001b[A\nGPU 1:  27%|██▋       | 376/1377 [00:15<00:19, 50.89it/s]\u001b[A\nGPU 1:  28%|██▊       | 382/1377 [00:15<00:18, 52.89it/s]\u001b[A\nGPU 1:  28%|██▊       | 388/1377 [00:15<00:18, 54.51it/s]\u001b[A\nGPU 1:  29%|██▊       | 394/1377 [00:15<00:17, 55.53it/s]\u001b[A\nGPU 1:  29%|██▉       | 400/1377 [00:15<00:17, 55.38it/s]\u001b[A\nGPU 1:  29%|██▉       | 406/1377 [00:15<00:17, 55.66it/s]\u001b[A\nGPU 1:  30%|██▉       | 412/1377 [00:16<00:17, 56.55it/s]\u001b[A\nGPU 1:  30%|███       | 418/1377 [00:16<00:16, 57.32it/s]\u001b[Alibpng warning: iCCP: known incorrect sRGB profile\n\nGPU 1:  31%|███       | 424/1377 [00:16<00:20, 46.08it/s]\u001b[A\nGPU 1:  31%|███       | 429/1377 [00:16<00:21, 44.97it/s]\u001b[A\nGPU 1:  32%|███▏      | 434/1377 [00:16<00:20, 44.99it/s]\u001b[A\nGPU 1:  32%|███▏      | 439/1377 [00:16<00:22, 41.80it/s]\u001b[A\nGPU 1:  32%|███▏      | 444/1377 [00:16<00:24, 38.05it/s]\u001b[A\nGPU 1:  33%|███▎      | 448/1377 [00:17<00:27, 33.99it/s]\u001b[A\nGPU 1:  33%|███▎      | 452/1377 [00:17<00:27, 33.83it/s]\u001b[A\nGPU 1:  33%|███▎      | 456/1377 [00:17<00:29, 31.00it/s]\u001b[A\nGPU 1:  33%|███▎      | 460/1377 [00:17<00:30, 30.28it/s]\u001b[A\nGPU 1:  34%|███▍      | 465/1377 [00:17<00:27, 32.82it/s]\u001b[Alibpng warning: iCCP: profile 'ICC Profile': 0h: PCS illuminant is not D50\n\nGPU 1:  34%|███▍      | 469/1377 [00:17<00:29, 31.30it/s]\u001b[A\nGPU 1:  34%|███▍      | 473/1377 [00:17<00:29, 31.15it/s]\u001b[A\nGPU 1:  35%|███▍      | 478/1377 [00:17<00:27, 33.11it/s]\u001b[A\nGPU 1:  35%|███▌      | 482/1377 [00:18<00:27, 32.14it/s]\u001b[A\nGPU 1:  35%|███▌      | 486/1377 [00:18<00:27, 32.03it/s]\u001b[Alibpng warning: iCCP: known incorrect sRGB profile\n\nGPU 1:  36%|███▌      | 490/1377 [00:18<00:30, 29.03it/s]\u001b[A\nGPU 1:  36%|███▌      | 493/1377 [00:18<00:30, 28.67it/s]\u001b[A\nGPU 1:  36%|███▌      | 497/1377 [00:18<00:28, 31.01it/s]\u001b[A\nGPU 1:  36%|███▋      | 501/1377 [00:18<00:28, 30.98it/s]\u001b[A\nGPU 1:  37%|███▋      | 506/1377 [00:18<00:25, 34.42it/s]\u001b[A\nGPU 1:  37%|███▋      | 510/1377 [00:18<00:24, 35.80it/s]\u001b[A\nGPU 1:  37%|███▋      | 516/1377 [00:19<00:21, 39.92it/s]\u001b[A\nGPU 1:  38%|███▊      | 521/1377 [00:19<00:21, 40.69it/s]\u001b[A\nGPU 1:  38%|███▊      | 526/1377 [00:19<00:20, 42.27it/s]\u001b[A\nGPU 1:  39%|███▊      | 531/1377 [00:19<00:21, 39.95it/s]\u001b[A\nGPU 1:  39%|███▉      | 536/1377 [00:19<00:27, 30.51it/s]\u001b[A\nGPU 1:  39%|███▉      | 542/1377 [00:19<00:23, 35.19it/s]\u001b[A\nGPU 1:  40%|███▉      | 546/1377 [00:19<00:26, 31.22it/s]\u001b[A\nGPU 1:  40%|███▉      | 550/1377 [00:20<00:31, 26.04it/s]\u001b[A\nGPU 1:  40%|████      | 555/1377 [00:20<00:27, 30.44it/s]\u001b[A\nGPU 1:  41%|████      | 561/1377 [00:20<00:22, 36.41it/s]\u001b[A\nGPU 1:  41%|████      | 566/1377 [00:20<00:30, 26.56it/s]\u001b[A\nGPU 1:  41%|████▏     | 570/1377 [00:21<00:36, 22.37it/s]\u001b[A\nGPU 1:  42%|████▏     | 573/1377 [00:21<00:39, 20.38it/s]\u001b[A\nGPU 1:  42%|████▏     | 576/1377 [00:21<00:41, 19.25it/s]\u001b[A\nGPU 1:  42%|████▏     | 579/1377 [00:21<00:44, 18.08it/s]\u001b[A\nGPU 1:  42%|████▏     | 581/1377 [00:21<00:50, 15.85it/s]\u001b[A\nGPU 1:  42%|████▏     | 583/1377 [00:21<00:52, 15.18it/s]\u001b[A\nGPU 1:  42%|████▏     | 585/1377 [00:22<00:53, 14.71it/s]\u001b[A\nGPU 1:  43%|████▎     | 587/1377 [00:22<00:59, 13.38it/s]\u001b[A\nGPU 1:  43%|████▎     | 590/1377 [00:22<00:52, 15.05it/s]\u001b[A\nGPU 1:  43%|████▎     | 592/1377 [00:22<01:01, 12.71it/s]\u001b[A\nGPU 1:  43%|████▎     | 594/1377 [00:22<01:05, 11.94it/s]\u001b[A\nGPU 1:  43%|████▎     | 596/1377 [00:23<01:10, 11.13it/s]\u001b[A\nGPU 1:  43%|████▎     | 598/1377 [00:23<01:06, 11.72it/s]\u001b[A\nGPU 1:  44%|████▎     | 601/1377 [00:23<00:58, 13.27it/s]\u001b[A\nGPU 1:  44%|████▍     | 603/1377 [00:23<00:56, 13.59it/s]\u001b[A\nGPU 1:  44%|████▍     | 608/1377 [00:23<00:45, 16.96it/s]\u001b[A\nGPU 1:  45%|████▍     | 613/1377 [00:23<00:34, 22.34it/s]\u001b[A\nGPU 1:  45%|████▍     | 616/1377 [00:24<00:34, 21.87it/s]\u001b[A\nGPU 1:  45%|████▌     | 621/1377 [00:24<00:27, 27.38it/s]\u001b[A\nGPU 1:  45%|████▌     | 626/1377 [00:24<00:23, 31.39it/s]\u001b[A\nGPU 1:  46%|████▌     | 630/1377 [00:24<00:24, 30.20it/s]\u001b[A\nGPU 1:  46%|████▌     | 634/1377 [00:24<00:37, 19.96it/s]\u001b[A\nGPU 1:  46%|████▋     | 637/1377 [00:25<00:43, 16.93it/s]\u001b[A\nGPU 1:  46%|████▋     | 640/1377 [00:25<00:45, 16.25it/s]\u001b[A\nGPU 1:  47%|████▋     | 642/1377 [00:25<00:49, 14.77it/s]\u001b[A\nGPU 1:  47%|████▋     | 644/1377 [00:25<00:49, 14.92it/s]\u001b[A\nGPU 1:  47%|████▋     | 646/1377 [00:25<01:01, 11.93it/s]\u001b[A\nGPU 1:  47%|████▋     | 648/1377 [00:26<01:10, 10.31it/s]\u001b[A\nGPU 1:  47%|████▋     | 651/1377 [00:26<01:00, 12.04it/s]\u001b[A\nGPU 1:  47%|████▋     | 653/1377 [00:26<00:55, 13.05it/s]\u001b[A\nGPU 1:  48%|████▊     | 655/1377 [00:26<00:57, 12.62it/s]\u001b[A\nGPU 1:  48%|████▊     | 657/1377 [00:26<00:53, 13.44it/s]\u001b[A\nGPU 1:  48%|████▊     | 661/1377 [00:26<00:56, 12.62it/s]\u001b[A\nGPU 1:  48%|████▊     | 664/1377 [00:27<00:52, 13.68it/s]\u001b[A\nGPU 1:  48%|████▊     | 666/1377 [00:27<00:51, 13.70it/s]\u001b[A\nGPU 1:  49%|████▊     | 669/1377 [00:27<00:47, 14.84it/s]\u001b[A\nGPU 1:  49%|████▉     | 673/1377 [00:27<00:36, 19.32it/s]\u001b[A\nGPU 1:  49%|████▉     | 677/1377 [00:27<00:34, 20.18it/s]\u001b[A\nGPU 1:  49%|████▉     | 680/1377 [00:27<00:34, 20.16it/s]\u001b[A\nGPU 1:  50%|████▉     | 683/1377 [00:28<00:40, 17.07it/s]\u001b[A\nGPU 1:  50%|████▉     | 685/1377 [00:28<00:59, 11.71it/s]\u001b[A\nGPU 1:  50%|█████     | 690/1377 [00:28<00:40, 17.07it/s]\u001b[A\nGPU 1:  50%|█████     | 693/1377 [00:28<00:39, 17.45it/s]\u001b[A\nGPU 1:  51%|█████     | 697/1377 [00:28<00:32, 21.17it/s]\u001b[A\nGPU 1:  51%|█████     | 700/1377 [00:29<00:40, 16.57it/s]\u001b[A\nGPU 1:  51%|█████     | 703/1377 [00:29<00:37, 17.79it/s]\u001b[A\nGPU 1:  51%|█████▏    | 706/1377 [00:29<00:36, 18.23it/s]\u001b[A\nGPU 1:  52%|█████▏    | 710/1377 [00:29<00:30, 21.98it/s]\u001b[A\nGPU 1:  52%|█████▏    | 713/1377 [00:29<00:30, 21.45it/s]\u001b[A\nGPU 1:  52%|█████▏    | 719/1377 [00:29<00:22, 29.23it/s]\u001b[A\nGPU 1:  53%|█████▎    | 725/1377 [00:29<00:18, 35.43it/s]\u001b[A\nGPU 1:  53%|█████▎    | 731/1377 [00:30<00:16, 40.26it/s]\u001b[A\nGPU 1:  54%|█████▎    | 737/1377 [00:30<00:14, 44.30it/s]\u001b[A\nGPU 1:  54%|█████▍    | 743/1377 [00:30<00:13, 47.30it/s]\u001b[A\nGPU 1:  54%|█████▍    | 749/1377 [00:30<00:12, 49.15it/s]\u001b[A\nGPU 1:  55%|█████▍    | 755/1377 [00:30<00:12, 50.91it/s]\u001b[A\nGPU 1:  55%|█████▌    | 761/1377 [00:30<00:11, 52.31it/s]\u001b[A\nGPU 1:  56%|█████▌    | 767/1377 [00:30<00:11, 53.07it/s]\u001b[A\nGPU 1:  56%|█████▌    | 773/1377 [00:30<00:11, 52.07it/s]\u001b[A\nGPU 1:  57%|█████▋    | 779/1377 [00:31<00:12, 49.03it/s]\u001b[A\nGPU 1:  57%|█████▋    | 784/1377 [00:31<00:12, 46.71it/s]\u001b[A\nGPU 1:  57%|█████▋    | 789/1377 [00:31<00:12, 45.97it/s]\u001b[A\nGPU 1:  58%|█████▊    | 795/1377 [00:31<00:12, 48.10it/s]\u001b[A\nGPU 1:  58%|█████▊    | 801/1377 [00:31<00:11, 50.18it/s]\u001b[A\nGPU 1:  59%|█████▊    | 807/1377 [00:31<00:11, 51.64it/s]\u001b[A\nGPU 1:  59%|█████▉    | 813/1377 [00:31<00:10, 51.95it/s]\u001b[A\nGPU 1:  59%|█████▉    | 819/1377 [00:31<00:10, 53.25it/s]\u001b[A\nGPU 1:  60%|█████▉    | 825/1377 [00:31<00:10, 53.45it/s]\u001b[A\nGPU 1:  60%|██████    | 831/1377 [00:32<00:16, 32.23it/s]\u001b[A\nGPU 1:  61%|██████    | 836/1377 [00:32<00:26, 20.65it/s]\u001b[A\nGPU 1:  61%|██████    | 840/1377 [00:33<00:33, 16.03it/s]\u001b[A\nGPU 1:  61%|██████    | 843/1377 [00:33<00:34, 15.43it/s]\u001b[A\nGPU 1:  61%|██████▏   | 846/1377 [00:33<00:36, 14.39it/s]\u001b[A\nGPU 1:  62%|██████▏   | 848/1377 [00:33<00:36, 14.36it/s]\u001b[A\nGPU 1:  62%|██████▏   | 853/1377 [00:33<00:26, 19.46it/s]\u001b[A\nGPU 1:  62%|██████▏   | 857/1377 [00:34<00:22, 22.95it/s]\u001b[A\nGPU 1:  63%|██████▎   | 862/1377 [00:34<00:18, 27.53it/s]\u001b[A\nGPU 1:  63%|██████▎   | 866/1377 [00:34<00:16, 30.15it/s]\u001b[A\nGPU 1:  63%|██████▎   | 870/1377 [00:34<00:19, 26.53it/s]\u001b[A\nGPU 1:  63%|██████▎   | 874/1377 [00:34<00:19, 25.97it/s]\u001b[A\nGPU 1:  64%|██████▍   | 878/1377 [00:34<00:20, 24.47it/s]\u001b[A\nGPU 1:  64%|██████▍   | 881/1377 [00:35<00:24, 20.13it/s]\u001b[A\nGPU 1:  64%|██████▍   | 886/1377 [00:35<00:19, 25.31it/s]\u001b[A\nGPU 1:  65%|██████▍   | 889/1377 [00:35<00:26, 18.76it/s]\u001b[A\nGPU 1:  65%|██████▍   | 892/1377 [00:35<00:29, 16.30it/s]\u001b[A\nGPU 1:  65%|██████▍   | 895/1377 [00:35<00:27, 17.46it/s]\u001b[A\nGPU 1:  65%|██████▌   | 898/1377 [00:36<00:35, 13.47it/s]\u001b[A\nGPU 1:  66%|██████▌   | 902/1377 [00:36<00:30, 15.83it/s]\u001b[A\nGPU 1:  66%|██████▌   | 904/1377 [00:36<00:30, 15.37it/s]\u001b[A\nGPU 1:  66%|██████▌   | 906/1377 [00:36<00:37, 12.45it/s]\u001b[A\nGPU 1:  66%|██████▌   | 908/1377 [00:36<00:42, 11.13it/s]\u001b[A\nGPU 1:  66%|██████▌   | 910/1377 [00:37<00:39, 11.70it/s]\u001b[A\nGPU 1:  66%|██████▌   | 912/1377 [00:37<00:46,  9.96it/s]\u001b[A\nGPU 1:  66%|██████▋   | 914/1377 [00:37<00:45, 10.12it/s]\u001b[A\nGPU 1:  67%|██████▋   | 916/1377 [00:37<00:42, 10.88it/s]\u001b[A\nGPU 1:  67%|██████▋   | 918/1377 [00:37<00:44, 10.25it/s]\u001b[A\nGPU 1:  67%|██████▋   | 920/1377 [00:38<00:39, 11.62it/s]\u001b[A\nGPU 1:  67%|██████▋   | 922/1377 [00:38<00:38, 11.97it/s]\u001b[A\nGPU 1:  67%|██████▋   | 924/1377 [00:38<00:42, 10.54it/s]\u001b[A\nGPU 1:  67%|██████▋   | 926/1377 [00:38<00:40, 11.26it/s]\u001b[A\nGPU 1:  68%|██████▊   | 932/1377 [00:38<00:21, 20.28it/s]\u001b[A\nGPU 1:  68%|██████▊   | 938/1377 [00:38<00:15, 28.32it/s]\u001b[A\nGPU 1:  69%|██████▊   | 944/1377 [00:38<00:12, 35.25it/s]\u001b[A\nGPU 1:  69%|██████▉   | 950/1377 [00:39<00:10, 40.69it/s]\u001b[A\nGPU 1:  69%|██████▉   | 956/1377 [00:39<00:09, 44.02it/s]\u001b[A\nGPU 1:  70%|██████▉   | 962/1377 [00:39<00:08, 47.49it/s]\u001b[A\nGPU 1:  70%|███████   | 968/1377 [00:39<00:08, 49.19it/s]\u001b[A\nGPU 1:  71%|███████   | 974/1377 [00:39<00:08, 49.13it/s]\u001b[A\nGPU 1:  71%|███████   | 980/1377 [00:39<00:07, 51.22it/s]\u001b[A\nGPU 1:  72%|███████▏  | 986/1377 [00:39<00:07, 52.86it/s]\u001b[A\nGPU 1:  72%|███████▏  | 992/1377 [00:39<00:07, 53.85it/s]\u001b[A\nGPU 1:  72%|███████▏  | 998/1377 [00:39<00:06, 54.59it/s]\u001b[A\nGPU 1:  73%|███████▎  | 1004/1377 [00:40<00:06, 55.23it/s]\u001b[A\nGPU 1:  73%|███████▎  | 1010/1377 [00:40<00:06, 54.91it/s]\u001b[A\nGPU 1:  74%|███████▍  | 1016/1377 [00:40<00:06, 54.64it/s]\u001b[A\nGPU 1:  74%|███████▍  | 1022/1377 [00:40<00:06, 54.76it/s]\u001b[A\nGPU 1:  75%|███████▍  | 1028/1377 [00:40<00:06, 53.60it/s]\u001b[A\nGPU 1:  75%|███████▌  | 1034/1377 [00:40<00:06, 54.47it/s]\u001b[A\nGPU 1:  76%|███████▌  | 1040/1377 [00:40<00:06, 55.11it/s]\u001b[A\nGPU 1:  76%|███████▌  | 1046/1377 [00:40<00:06, 54.41it/s]\u001b[A\nGPU 1:  76%|███████▋  | 1052/1377 [00:40<00:05, 54.91it/s]\u001b[A\nGPU 1:  77%|███████▋  | 1058/1377 [00:41<00:05, 54.39it/s]\u001b[A\nGPU 1:  77%|███████▋  | 1064/1377 [00:41<00:05, 54.69it/s]\u001b[A\nGPU 1:  78%|███████▊  | 1070/1377 [00:41<00:05, 55.28it/s]\u001b[A\nGPU 1:  78%|███████▊  | 1076/1377 [00:41<00:05, 55.14it/s]\u001b[A\nGPU 1:  79%|███████▊  | 1082/1377 [00:41<00:05, 55.51it/s]\u001b[A\nGPU 1:  79%|███████▉  | 1088/1377 [00:41<00:05, 55.71it/s]\u001b[A\nGPU 1:  79%|███████▉  | 1094/1377 [00:41<00:05, 55.69it/s]\u001b[A\nGPU 1:  80%|███████▉  | 1100/1377 [00:41<00:04, 55.54it/s]\u001b[A\nGPU 1:  80%|████████  | 1106/1377 [00:41<00:04, 55.27it/s]\u001b[A\nGPU 1:  81%|████████  | 1112/1377 [00:42<00:04, 55.77it/s]\u001b[A\nGPU 1:  81%|████████  | 1118/1377 [00:42<00:04, 56.12it/s]\u001b[A\nGPU 1:  82%|████████▏ | 1124/1377 [00:42<00:04, 54.91it/s]\u001b[A\nGPU 1:  82%|████████▏ | 1130/1377 [00:42<00:04, 54.89it/s]\u001b[A\nGPU 1:  82%|████████▏ | 1136/1377 [00:42<00:04, 55.25it/s]\u001b[A\nGPU 1:  83%|████████▎ | 1142/1377 [00:42<00:04, 55.95it/s]\u001b[A\nGPU 1:  83%|████████▎ | 1148/1377 [00:42<00:04, 56.59it/s]\u001b[A\nGPU 1:  84%|████████▍ | 1154/1377 [00:42<00:04, 55.51it/s]\u001b[A\nGPU 1:  84%|████████▍ | 1160/1377 [00:42<00:03, 54.91it/s]\u001b[A\nGPU 1:  85%|████████▍ | 1166/1377 [00:42<00:03, 54.95it/s]\u001b[A\nGPU 1:  85%|████████▌ | 1172/1377 [00:43<00:03, 55.34it/s]\u001b[A\nGPU 1:  86%|████████▌ | 1178/1377 [00:43<00:03, 55.46it/s]\u001b[A\nGPU 1:  86%|████████▌ | 1184/1377 [00:43<00:03, 56.61it/s]\u001b[A\nGPU 1:  86%|████████▋ | 1190/1377 [00:43<00:03, 55.47it/s]\u001b[A\nGPU 1:  87%|████████▋ | 1196/1377 [00:43<00:03, 47.51it/s]\u001b[A\nGPU 1:  87%|████████▋ | 1201/1377 [00:43<00:04, 38.24it/s]\u001b[A\nGPU 1:  88%|████████▊ | 1206/1377 [00:43<00:04, 38.85it/s]\u001b[A\nGPU 1:  88%|████████▊ | 1211/1377 [00:44<00:04, 40.09it/s]\u001b[A\nGPU 1:  88%|████████▊ | 1216/1377 [00:44<00:03, 40.91it/s]\u001b[A\nGPU 1:  89%|████████▊ | 1221/1377 [00:44<00:04, 31.42it/s]\u001b[Alibpng warning: iCCP: known incorrect sRGB profile\n\nGPU 1:  89%|████████▉ | 1225/1377 [00:44<00:05, 30.32it/s]\u001b[A\nGPU 1:  89%|████████▉ | 1230/1377 [00:44<00:04, 33.46it/s]\u001b[A\nGPU 1:  90%|████████▉ | 1234/1377 [00:44<00:04, 32.40it/s]\u001b[A\nGPU 1:  90%|████████▉ | 1238/1377 [00:44<00:04, 31.03it/s]\u001b[A\nGPU 1:  90%|█████████ | 1242/1377 [00:45<00:05, 26.33it/s]\u001b[A\nGPU 1:  90%|█████████ | 1245/1377 [00:45<00:05, 25.69it/s]\u001b[A\nGPU 1:  91%|█████████ | 1248/1377 [00:45<00:05, 23.00it/s]\u001b[A\nGPU 1:  91%|█████████ | 1252/1377 [00:45<00:05, 22.57it/s]\u001b[A\nGPU 1:  91%|█████████ | 1255/1377 [00:45<00:05, 23.70it/s]\u001b[A\nGPU 1:  92%|█████████▏| 1260/1377 [00:45<00:04, 28.39it/s]\u001b[A\nGPU 1:  92%|█████████▏| 1264/1377 [00:46<00:04, 25.42it/s]\u001b[A\nGPU 1:  92%|█████████▏| 1268/1377 [00:46<00:03, 27.86it/s]\u001b[A\nGPU 1:  92%|█████████▏| 1273/1377 [00:46<00:03, 32.25it/s]\u001b[A\nGPU 1:  93%|█████████▎| 1278/1377 [00:46<00:02, 35.12it/s]\u001b[A\nGPU 1:  93%|█████████▎| 1283/1377 [00:46<00:02, 37.32it/s]\u001b[A\nGPU 1:  94%|█████████▎| 1288/1377 [00:46<00:02, 39.93it/s]\u001b[A\nGPU 1:  94%|█████████▍| 1293/1377 [00:46<00:02, 36.81it/s]\u001b[A\nGPU 1:  94%|█████████▍| 1298/1377 [00:46<00:02, 39.04it/s]\u001b[A\nGPU 1:  95%|█████████▍| 1303/1377 [00:46<00:01, 40.83it/s]\u001b[A\nGPU 1:  95%|█████████▍| 1308/1377 [00:47<00:01, 40.20it/s]\u001b[A\nGPU 1:  95%|█████████▌| 1313/1377 [00:47<00:03, 19.73it/s]\u001b[A\nGPU 1:  96%|█████████▌| 1317/1377 [00:48<00:04, 14.26it/s]\u001b[A\nGPU 1:  96%|█████████▌| 1320/1377 [00:48<00:04, 14.05it/s]\u001b[A\nGPU 1:  96%|█████████▌| 1323/1377 [00:48<00:03, 14.29it/s]\u001b[A\nGPU 1:  96%|█████████▌| 1325/1377 [00:48<00:03, 14.12it/s]\u001b[A\nGPU 1:  96%|█████████▋| 1327/1377 [00:49<00:04, 12.10it/s]\u001b[A\nGPU 1:  97%|█████████▋| 1329/1377 [00:49<00:04, 11.46it/s]\u001b[A\nGPU 1:  97%|█████████▋| 1331/1377 [00:49<00:04, 11.04it/s]\u001b[A\nGPU 1:  97%|█████████▋| 1333/1377 [00:49<00:04, 10.29it/s]\u001b[A\nGPU 1:  97%|█████████▋| 1335/1377 [00:49<00:04,  8.88it/s]\u001b[A\nGPU 1:  97%|█████████▋| 1336/1377 [00:50<00:04,  8.83it/s]\u001b[A\nGPU 1:  97%|█████████▋| 1337/1377 [00:50<00:04,  8.53it/s]\u001b[A\nGPU 1:  97%|█████████▋| 1339/1377 [00:50<00:03,  9.70it/s]\u001b[A\nGPU 1:  97%|█████████▋| 1341/1377 [00:50<00:04,  8.68it/s]\u001b[A\nGPU 1:  97%|█████████▋| 1342/1377 [00:50<00:04,  8.20it/s]\u001b[A\nGPU 1:  98%|█████████▊| 1343/1377 [00:50<00:04,  8.12it/s]\u001b[A\nGPU 1:  98%|█████████▊| 1347/1377 [00:51<00:02, 14.43it/s]\u001b[A\nGPU 1:  98%|█████████▊| 1350/1377 [00:51<00:01, 17.29it/s]\u001b[A\nGPU 1:  98%|█████████▊| 1354/1377 [00:51<00:01, 21.53it/s]\u001b[Alibpng warning: iCCP: known incorrect sRGB profile\n\nGPU 1:  99%|█████████▊| 1358/1377 [00:51<00:00, 22.22it/s]\u001b[A\nGPU 1:  99%|█████████▉| 1363/1377 [00:51<00:00, 27.94it/s]\u001b[A\nGPU 1:  99%|█████████▉| 1367/1377 [00:51<00:00, 28.55it/s]\u001b[A\nGPU 1: 100%|█████████▉| 1371/1377 [00:51<00:00, 25.64it/s]\u001b[A\nGPU 1: 100%|██████████| 1377/1377 [00:52<00:00, 26.41it/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"✅ Preprocessing complete — CSV saved at: /kaggle/working/merged_dataset/labels.csv\nbreed\nSahiwal              427\nGir                  369\nHolstein_Friesian    309\nAyrshire             222\nTharparkar           208\nBrown_Swiss          206\nOngole               187\nJersey               184\nHallikar             180\nNagpuri              175\nKankrej              173\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Custom transform for blur, brightness, JPEG compression\nclass RandomImageQuality:\n    def __init__(self, p_blur=0.5, p_jpeg=0.5):\n        self.p_blur = p_blur\n        self.p_jpeg = p_jpeg\n\n    def __call__(self, img):\n        # Random blur\n        if random.random() < self.p_blur:\n            img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.5, 2.0)))\n        # Random JPEG compression\n        if random.random() < self.p_jpeg:\n            buffer = io.BytesIO()\n            quality = random.randint(30, 90)\n            img.save(buffer, format='JPEG', quality=quality)\n            buffer.seek(0)\n            img = Image.open(buffer)\n        return img\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:08:59.868869Z","iopub.execute_input":"2025-09-30T16:08:59.869074Z","iopub.status.idle":"2025-09-30T16:08:59.874684Z","shell.execute_reply.started":"2025-09-30T16:08:59.869059Z","shell.execute_reply":"2025-09-30T16:08:59.874058Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from PIL import Image\nimport random\nimport torchvision.transforms as transforms\nimport torch\n\nclass RandomOcclusion:\n    def __init__(self, p=0.5, size=(20,50)):\n        self.p = p          # probability of applying occlusion\n        self.size = size    # min-max size of occlusion block in pixels\n\n    def __call__(self, img):\n        if random.random() < self.p:\n            w, h = img.size\n            # Random width and height of obstruction\n            occ_w = random.randint(self.size[0], self.size[1])\n            occ_h = random.randint(self.size[0], self.size[1])\n            # Random top-left position\n            x1 = random.randint(0, w - occ_w)\n            y1 = random.randint(0, h - occ_h)\n            # Draw black rectangle as obstruction\n            img_pil = img.copy()\n            from PIL import ImageDraw\n            draw = ImageDraw.Draw(img_pil)\n            draw.rectangle([x1, y1, x1+occ_w, y1+occ_h], fill=(0,0,0))\n            img = img_pil\n        return img\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:08:59.896064Z","iopub.execute_input":"2025-09-30T16:08:59.896323Z","iopub.status.idle":"2025-09-30T16:08:59.918478Z","shell.execute_reply.started":"2025-09-30T16:08:59.896307Z","shell.execute_reply":"2025-09-30T16:08:59.917901Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import torchvision.transforms as transforms\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((300, 300)),  # Resize PIL image\n\n    transforms.RandomApply([RandomImageQuality()], p=0.2),\n    transforms.RandomApply([transforms.ColorJitter(\n        brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05\n    )], p=0.3),\n    transforms.RandomApply([transforms.RandomRotation(degrees=30)], p=0.3),\n    transforms.RandomPerspective(distortion_scale=0.3, p=0.3),\n    RandomOcclusion(p=0.3, size=(20,50)),\n\n    transforms.ToTensor(),  # Convert PIL -> Tensor\n\n    #transforms.RandomErasing(p=0.2, scale=(0.02,0.2), ratio=(0.3,3.3)),  # Tensor only\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((300, 300)),\n    transforms.ToTensor()\n])\n\nprint(\"✅ Transforms ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:08:59.919155Z","iopub.execute_input":"2025-09-30T16:08:59.919391Z","iopub.status.idle":"2025-09-30T16:08:59.938734Z","shell.execute_reply.started":"2025-09-30T16:08:59.919370Z","shell.execute_reply":"2025-09-30T16:08:59.938184Z"}},"outputs":[{"name":"stdout","text":"✅ Transforms ready\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"✅ Using device:\", device)\n\n\n\n\n# --- Assign folds for K-Fold cross-validation ---\nK = 5\nskf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\ndf[\"fold\"] = -1\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df[\"image_path\"], df[\"breed\"])):\n    df.loc[val_idx, \"fold\"] = fold\n\n# Save fold info\ndf.to_csv(csv_path, index=False)\nprint(f\"✅ Assigned {K} folds for cross-validation\")\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:08:59.939353Z","iopub.execute_input":"2025-09-30T16:08:59.939582Z","iopub.status.idle":"2025-09-30T16:08:59.979308Z","shell.execute_reply.started":"2025-09-30T16:08:59.939566Z","shell.execute_reply":"2025-09-30T16:08:59.978662Z"}},"outputs":[{"name":"stdout","text":"✅ Using device: cuda\n✅ Assigned 5 folds for cross-validation\nDone\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"class FoldDataset(Dataset):\n    \"\"\"\n    Custom dataset for K-Fold training.\n    \"\"\"\n    def __init__(self, df, fold, train=True, transform=None):\n        self.transform = transform\n        self.classes = sorted(df[\"breed\"].unique())\n        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n        self.data = df[df[\"fold\"] != fold] if train else df[df[\"fold\"] == fold]\n        self.data = self.data.reset_index(drop=True)\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        img_path = os.path.join(merged_base, row[\"image_path\"])\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        label = self.class_to_idx[row[\"breed\"]]\n        return img, label\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:09:10.129075Z","iopub.execute_input":"2025-09-30T16:09:10.129657Z","iopub.status.idle":"2025-09-30T16:09:10.136190Z","shell.execute_reply.started":"2025-09-30T16:09:10.129633Z","shell.execute_reply":"2025-09-30T16:09:10.135339Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"val_fold = 0  \n\n# Training set = all folds except 0\ntrain_df = df[df[\"fold\"] != val_fold].reset_index(drop=True)\n\n# Validation set = only fold 0\nval_df   = df[df[\"fold\"] == val_fold].reset_index(drop=True)\n\ntrain_dataset = FoldDataset(train_df, fold=val_fold, train=True, transform=train_transforms)\nval_dataset   = FoldDataset(val_df, fold=val_fold, train=False, transform=val_transforms)\nprint(\"Done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:09:13.444196Z","iopub.execute_input":"2025-09-30T16:09:13.444464Z","iopub.status.idle":"2025-09-30T16:09:13.455351Z","shell.execute_reply.started":"2025-09-30T16:09:13.444444Z","shell.execute_reply":"2025-09-30T16:09:13.454570Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# --- STEP 10: SETUP TRAINING ---\n\n\nbatch_size = 16\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n\n\n\nprint(\"✅ Training setup complete\")\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:09:15.910684Z","iopub.execute_input":"2025-09-30T16:09:15.910957Z","iopub.status.idle":"2025-09-30T16:09:15.916494Z","shell.execute_reply.started":"2025-09-30T16:09:15.910936Z","shell.execute_reply":"2025-09-30T16:09:15.915839Z"}},"outputs":[{"name":"stdout","text":"✅ Training setup complete\nDone\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"best_val_acc = 0.0  # track best validation accuracy\n\n# --- Load pretrained EfficientNet-B3 ---\nmodel = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n\n# Freeze all layers initially\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace classifier to match number of cow breeds\nnum_classes = len(df[\"breed\"].unique())\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\nmodel = model.to(device)\n\n# --- Criterion ---\ncriterion = nn.CrossEntropyLoss()\n\n# --- Gradual unfreeze schedule ---\n# Each tuple: (phase_name, list of layers to unfreeze, learning_rate, epochs)\nphases = [\n    (\"Phase 1: Train classifier only\", [model.classifier], 1e-3, 20),\n    (\"Phase 2: Unfreeze last block (features[7])\", [model.features[7]], 1e-4, 10),\n    (\"Phase 3: Unfreeze second-to-last block (features[6])\", [model.features[6]], 1e-5, 5),\n    (\"Phase 4: Unfreeze third-to-last block (features[5])\", [model.features[5]], 5e-6, 5)\n]\n\nbest_val_loss = float('inf')\nbest_model_path = \"/kaggle/working/best_model.pth\"\n\n# --- Training loop with gradual unfreezing ---\nfor phase_name, layers_to_unfreeze, lr, epochs in phases:\n    # Unfreeze specified layers\n    for layer in layers_to_unfreeze:\n        for param in layer.parameters():\n            param.requires_grad = True\n\n    # Optimizer for trainable parameters\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n\n    # Scheduler reduces LR if val_loss plateaus\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n\n    print(f\"\\n=== {phase_name} ===\")\n\n    for epoch in range(epochs):\n        # --- Training ---\n        model.train()\n        train_loss = 0\n        all_train_labels = []\n        all_train_preds = []\n\n        for images, labels in train_loader:\n            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * images.size(0)\n            preds = outputs.argmax(dim=1)\n            all_train_labels.extend(labels.cpu().numpy())\n            all_train_preds.extend(preds.cpu().numpy())\n\n        train_loss /= len(train_loader.dataset)\n        train_acc = accuracy_score(all_train_labels, all_train_preds)\n        train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')\n\n        # --- Validation ---\n        model.eval()\n        val_loss = 0\n        all_val_labels = []\n        all_val_preds = []\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item() * images.size(0)\n\n                preds = outputs.argmax(dim=1)\n                all_val_labels.extend(labels.cpu().numpy())\n                all_val_preds.extend(preds.cpu().numpy())\n\n        val_loss /= len(val_loader.dataset)\n        val_acc = accuracy_score(all_val_labels, all_val_preds)\n        val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')\n\n        # Step scheduler\n        scheduler.step(val_loss)\n\n        print(f\"Epoch {epoch+1}/{epochs} | \"\n              f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n              f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n\n        # Save best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"✅ Best model updated (Val Acc: {best_val_acc:.4f})\")\n\n\nprint(f\"\\n🏆 Training complete. Best model saved at {best_model_path}\")\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:09:19.197827Z","iopub.execute_input":"2025-09-30T16:09:19.198094Z","iopub.status.idle":"2025-09-30T16:20:43.695943Z","shell.execute_reply.started":"2025-09-30T16:09:19.198077Z","shell.execute_reply":"2025-09-30T16:20:43.695176Z"}},"outputs":[{"name":"stdout","text":"\n=== Phase 1: Train classifier only ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20 | Train Loss: 1.8063, Acc: 0.4171, F1: 0.3984 | Val Loss: 1.3422, Acc: 0.6326, F1: 0.6221\n✅ Best model updated (Val Acc: 0.6326)\nEpoch 2/20 | Train Loss: 1.2898, Acc: 0.5994, F1: 0.5935 | Val Loss: 1.0951, Acc: 0.6913, F1: 0.6902\n✅ Best model updated (Val Acc: 0.6913)\nEpoch 3/20 | Train Loss: 1.1193, Acc: 0.6539, F1: 0.6500 | Val Loss: 4.2971, Acc: 0.7064, F1: 0.7068\n✅ Best model updated (Val Acc: 0.7064)\nEpoch 4/20 | Train Loss: 1.0553, Acc: 0.6667, F1: 0.6637 | Val Loss: 3.1902, Acc: 0.7178, F1: 0.7186\n✅ Best model updated (Val Acc: 0.7178)\nEpoch 5/20 | Train Loss: 1.0034, Acc: 0.6742, F1: 0.6716 | Val Loss: 1.3333, Acc: 0.7216, F1: 0.7178\n✅ Best model updated (Val Acc: 0.7216)\nEpoch 6/20 | Train Loss: 0.9423, Acc: 0.7055, F1: 0.7034 | Val Loss: 1.2641, Acc: 0.7292, F1: 0.7284\n✅ Best model updated (Val Acc: 0.7292)\nEpoch 7/20 | Train Loss: 0.9407, Acc: 0.6941, F1: 0.6924 | Val Loss: 1.2415, Acc: 0.7367, F1: 0.7374\n✅ Best model updated (Val Acc: 0.7367)\nEpoch 8/20 | Train Loss: 0.9368, Acc: 0.7050, F1: 0.7038 | Val Loss: 1.0388, Acc: 0.7443, F1: 0.7445\n✅ Best model updated (Val Acc: 0.7443)\nEpoch 9/20 | Train Loss: 0.9185, Acc: 0.7050, F1: 0.7036 | Val Loss: 1.1969, Acc: 0.7519, F1: 0.7506\n✅ Best model updated (Val Acc: 0.7519)\nEpoch 10/20 | Train Loss: 0.8709, Acc: 0.7292, F1: 0.7278 | Val Loss: 2.5900, Acc: 0.7292, F1: 0.7298\nEpoch 11/20 | Train Loss: 0.8826, Acc: 0.7197, F1: 0.7181 | Val Loss: 1.3747, Acc: 0.7405, F1: 0.7402\nEpoch 12/20 | Train Loss: 0.8559, Acc: 0.7197, F1: 0.7190 | Val Loss: 1.2363, Acc: 0.7386, F1: 0.7381\nEpoch 13/20 | Train Loss: 0.8512, Acc: 0.7206, F1: 0.7199 | Val Loss: 1.3413, Acc: 0.7462, F1: 0.7452\nEpoch 14/20 | Train Loss: 0.8845, Acc: 0.7173, F1: 0.7152 | Val Loss: 2.0206, Acc: 0.7348, F1: 0.7339\nEpoch 15/20 | Train Loss: 0.8492, Acc: 0.7348, F1: 0.7330 | Val Loss: 1.9076, Acc: 0.7500, F1: 0.7489\nEpoch 16/20 | Train Loss: 0.8496, Acc: 0.7259, F1: 0.7248 | Val Loss: 5.6930, Acc: 0.7386, F1: 0.7377\nEpoch 17/20 | Train Loss: 0.8469, Acc: 0.7315, F1: 0.7304 | Val Loss: 10.1661, Acc: 0.7443, F1: 0.7434\nEpoch 18/20 | Train Loss: 0.8477, Acc: 0.7244, F1: 0.7226 | Val Loss: 8.6437, Acc: 0.7273, F1: 0.7272\nEpoch 19/20 | Train Loss: 0.8470, Acc: 0.7225, F1: 0.7212 | Val Loss: 1.2686, Acc: 0.7292, F1: 0.7285\nEpoch 20/20 | Train Loss: 0.8244, Acc: 0.7457, F1: 0.7448 | Val Loss: 3.1521, Acc: 0.7216, F1: 0.7230\n\n=== Phase 2: Unfreeze last block (features[7]) ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 | Train Loss: 0.8085, Acc: 0.7296, F1: 0.7285 | Val Loss: 1.4728, Acc: 0.7708, F1: 0.7694\n✅ Best model updated (Val Acc: 0.7708)\nEpoch 2/10 | Train Loss: 0.7127, Acc: 0.7704, F1: 0.7693 | Val Loss: 14.3140, Acc: 0.7614, F1: 0.7622\nEpoch 3/10 | Train Loss: 0.6587, Acc: 0.7850, F1: 0.7843 | Val Loss: 2.9162, Acc: 0.7765, F1: 0.7755\n✅ Best model updated (Val Acc: 0.7765)\nEpoch 4/10 | Train Loss: 0.6048, Acc: 0.8054, F1: 0.8050 | Val Loss: 0.6917, Acc: 0.7898, F1: 0.7888\n✅ Best model updated (Val Acc: 0.7898)\nEpoch 5/10 | Train Loss: 0.5441, Acc: 0.8338, F1: 0.8330 | Val Loss: 0.7871, Acc: 0.7879, F1: 0.7879\nEpoch 6/10 | Train Loss: 0.5788, Acc: 0.8120, F1: 0.8114 | Val Loss: 1.1290, Acc: 0.7917, F1: 0.7910\n✅ Best model updated (Val Acc: 0.7917)\nEpoch 7/10 | Train Loss: 0.4967, Acc: 0.8485, F1: 0.8481 | Val Loss: 1.9190, Acc: 0.8030, F1: 0.8023\n✅ Best model updated (Val Acc: 0.8030)\nEpoch 8/10 | Train Loss: 0.4448, Acc: 0.8580, F1: 0.8576 | Val Loss: 15.7956, Acc: 0.7898, F1: 0.7886\nEpoch 9/10 | Train Loss: 0.4446, Acc: 0.8565, F1: 0.8565 | Val Loss: 0.8014, Acc: 0.7784, F1: 0.7771\nEpoch 10/10 | Train Loss: 0.4219, Acc: 0.8750, F1: 0.8748 | Val Loss: 4.2526, Acc: 0.7841, F1: 0.7832\n\n=== Phase 3: Unfreeze second-to-last block (features[6]) ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 | Train Loss: 0.4324, Acc: 0.8603, F1: 0.8600 | Val Loss: 1.1098, Acc: 0.7898, F1: 0.7883\nEpoch 2/5 | Train Loss: 0.4114, Acc: 0.8693, F1: 0.8692 | Val Loss: 2.4254, Acc: 0.7879, F1: 0.7872\nEpoch 3/5 | Train Loss: 0.4135, Acc: 0.8712, F1: 0.8709 | Val Loss: 1.8365, Acc: 0.8011, F1: 0.8006\nEpoch 4/5 | Train Loss: 0.3745, Acc: 0.8911, F1: 0.8910 | Val Loss: 4.9293, Acc: 0.7898, F1: 0.7886\nEpoch 5/5 | Train Loss: 0.3782, Acc: 0.8892, F1: 0.8890 | Val Loss: 1.2838, Acc: 0.7973, F1: 0.7961\n\n=== Phase 4: Unfreeze third-to-last block (features[5]) ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 | Train Loss: 0.3312, Acc: 0.9020, F1: 0.9016 | Val Loss: 1.3982, Acc: 0.8030, F1: 0.8024\nEpoch 2/5 | Train Loss: 0.3612, Acc: 0.8854, F1: 0.8852 | Val Loss: 4.5401, Acc: 0.7860, F1: 0.7852\nEpoch 3/5 | Train Loss: 0.3591, Acc: 0.8977, F1: 0.8974 | Val Loss: 5.9157, Acc: 0.7955, F1: 0.7946\nEpoch 4/5 | Train Loss: 0.3691, Acc: 0.8883, F1: 0.8880 | Val Loss: 0.8564, Acc: 0.7973, F1: 0.7962\nEpoch 5/5 | Train Loss: 0.3490, Acc: 0.8864, F1: 0.8861 | Val Loss: 2.9499, Acc: 0.7879, F1: 0.7869\n\n🏆 Training complete. Best model saved at /kaggle/working/best_model.pth\nDone\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import torch\n\n# Map to available device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Load model weights safely\nmodel.load_state_dict(torch.load(best_model_path, map_location=device))\nmodel.to(device)  # move model to the device\nmodel.eval()\n\nprint(\"✅ Model loaded and ready for inference on\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:20:49.304706Z","iopub.execute_input":"2025-09-30T16:20:49.304999Z","iopub.status.idle":"2025-09-30T16:20:49.513487Z","shell.execute_reply.started":"2025-09-30T16:20:49.304973Z","shell.execute_reply":"2025-09-30T16:20:49.512751Z"}},"outputs":[{"name":"stdout","text":"✅ Model loaded and ready for inference on cuda:0\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# ---------------- Prepare export folder ----------------\nimport os, shutil, json, subprocess\n\nmerged_base = '/kaggle/working/merged_dataset'\nbest_model_path = '/kaggle/working/best_model.pth'\nexport_dir = '/kaggle/working/export_dataset'\nos.makedirs(export_dir, exist_ok=True)\n\n# Copy preprocessed dataset\nif not os.path.exists(merged_base):\n    raise FileNotFoundError(f\"Preprocessed dataset not found at {merged_base} - run preprocessing first.\")\nshutil.copytree(merged_base, os.path.join(export_dir, 'merged_dataset'), dirs_exist_ok=True)\n\n# Copy best model if exists\nif os.path.exists(best_model_path):\n    shutil.copy2(best_model_path, os.path.join(export_dir, os.path.basename(best_model_path)))\nelse:\n    print(\"⚠️ best_model.pth not found — continuing without model.\")\n\n# Path to metadata\nmetadata_path = os.path.join(export_dir, 'dataset-metadata.json')\n\n# Create minimal metadata if missing\nif not os.path.exists(metadata_path):\n    meta = {\n        \"title\": \"cow dataset and model 11 breeds using yolo rj\",\n        \"id\": \"<username>/bovine_dataset_and_model\",  # placeholder\n        \"licenses\": [{\"name\": \"CC0-1.0\"}],\n        \"isPrivate\": True,\n        \"subtitle\": \"SAM-cropped bovine + calf images (optional model)\",\n        \"description\": \"Preprocessed dataset (Segment-Anything crops) plus optional trained model.\"\n    }\n    with open(metadata_path, 'w') as f:\n        json.dump(meta, f, indent=2)\n    print(\"✅ Created minimal dataset-metadata.json\")\n\nprint(\"✅ Export folder prepared at:\", export_dir)\nprint(\"Contents preview:\", os.listdir(export_dir)[:20])\nprint(\"Done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:20:53.004454Z","iopub.execute_input":"2025-09-30T16:20:53.004711Z","iopub.status.idle":"2025-09-30T16:20:53.353626Z","shell.execute_reply.started":"2025-09-30T16:20:53.004691Z","shell.execute_reply":"2025-09-30T16:20:53.352868Z"}},"outputs":[{"name":"stdout","text":"✅ Created minimal dataset-metadata.json\n✅ Export folder prepared at: /kaggle/working/export_dataset\nContents preview: ['dataset-metadata.json', 'merged_dataset', 'best_model.pth']\nDone\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# ---------------- Kaggle CLI setup ----------------\nkaggle_json_src = '/kaggle/input/kaggle-api/kaggle.json'\nkaggle_local = os.path.expanduser('~/.kaggle/kaggle.json')\n\n# Install kaggle CLI\n!pip install --quiet kaggle\n\n# Copy kaggle.json\nif os.path.exists(kaggle_local):\n    print(\"Found existing ~/.kaggle/kaggle.json — using it.\")\nelif os.path.exists(kaggle_json_src):\n    os.makedirs(os.path.dirname(kaggle_local), exist_ok=True)\n    shutil.copy2(kaggle_json_src, kaggle_local)\n    os.chmod(kaggle_local, 0o600)\n    print(f\"Copied kaggle.json from {kaggle_json_src} -> {kaggle_local}\")\nelse:\n    raise FileNotFoundError(\"kaggle.json not found. Upload it via notebook UI and re-run this cell.\")\n\n# Read username\nwith open(kaggle_local, 'r') as f:\n    kg = json.load(f)\nusername = kg.get('username') or kg.get('user') or kg.get('email') or None\n\n# Update metadata id if possible\nslug = 'cow-dataset-and-model-11breeds-using-yolo-rj'\nif username:\n    with open(metadata_path, 'r') as f:\n        meta = json.load(f)\n    meta['id'] = f\"{username}/{slug}\"\n    with open(metadata_path, 'w') as f:\n        json.dump(meta, f, indent=2)\n    print(f\"Dataset id set to: {meta['id']}\")\nelse:\n    print(\"⚠️ Could not determine username — dataset id in metadata will remain placeholder.\")\n\n# ---------------- Create or version Kaggle dataset ----------------\ncreate_cmd = f\"kaggle datasets create -p {export_dir} --dir-mode zip\"\nprint(\"Running:\", create_cmd)\nres = subprocess.run(create_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n\nif res.returncode == 0:\n    print(\"✅ Dataset created successfully.\")\n    print(res.stdout)\nelse:\n    print(\"Create failed; attempting to create a new version...\")\n    version_cmd = f\"kaggle datasets version -p {export_dir} -m \\\"Update: SAM preproc + optional model\\\" --dir-mode zip --force\"\n    print(\"Running:\", version_cmd)\n    res2 = subprocess.run(version_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n    if res2.returncode == 0:\n        print(\"✅ Dataset version created successfully.\")\n        print(res2.stdout)\n    else:\n        print(\"❌ Both create and version failed.\")\n        print(\"CREATE stderr:\\n\", res.stderr)\n        print(\"VERSION stderr:\\n\", res2.stderr)\n        raise RuntimeError(\"Failed to create/version Kaggle dataset. Check kaggle.json and metadata id.\")\n\n# ---------------- Dataset URL ----------------\nif username:\n    print(\"\\nDataset should be available at:\")\n    print(f\"https://www.kaggle.com/{username}/{slug}\")\nelse:\n    print(\"\\nDataset created/updated but username unknown. Check Kaggle web UI.\")\nprint(\"Done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:20:56.908834Z","iopub.execute_input":"2025-09-30T16:20:56.909525Z","iopub.status.idle":"2025-09-30T16:21:07.828168Z","shell.execute_reply.started":"2025-09-30T16:20:56.909499Z","shell.execute_reply":"2025-09-30T16:21:07.827400Z"}},"outputs":[{"name":"stdout","text":"Copied kaggle.json from /kaggle/input/kaggle-api/kaggle.json -> /root/.kaggle/kaggle.json\nDataset id set to: riddhijaiswal111/cow-dataset-and-model-11breeds-using-yolo-rj\nRunning: kaggle datasets create -p /kaggle/working/export_dataset --dir-mode zip\n✅ Dataset created successfully.\nStarting upload for file merged_dataset.zip\nUpload successful: merged_dataset.zip (86MB)\nStarting upload for file best_model.pth\nUpload successful: best_model.pth (41MB)\nYour private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/riddhijaiswal111/cow-dataset-and-model-11breeds-using-yolo-rj\n\n\nDataset should be available at:\nhttps://www.kaggle.com/riddhijaiswal111/cow-dataset-and-model-11breeds-using-yolo-rj\nDone\n","output_type":"stream"}],"execution_count":35}]}